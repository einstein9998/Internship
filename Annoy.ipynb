{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "import annoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#200000 compounds with 469 features\n",
    "all_features = pd.read_csv(\"c2vpoint2m.txt.gz\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the compound names the index\n",
    "all_features.set_index(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#725634 compounds with target and activity\n",
    "cgan = pd.read_csv(\"activities.txt.gz\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are only interested in the compounds whose target is EGFR\n",
    "egfr_activity = cgan[cgan['target'] == 'EGFR'].set_index('compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate into two dataframes, one with active compounds\n",
    "egfr_active = egfr_activity[egfr_activity['activity'] >= 6]\n",
    "egfr_active_compounds = egfr_active.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and one with inactive ones\n",
    "egfr_inactive = egfr_activity[egfr_activity['activity']  < 6]\n",
    "egfr_inactive_compounds = egfr_inactive.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5275 compounds with EGFR target and 469 features\n",
    "egfr_features = pd.read_csv(\"egfr.c2v.txt\", sep=\"\\t\", header=None).set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate the names for easier access\n",
    "egfr_compounds = egfr_features.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataframes with features for the active and inactive compounds\n",
    "egfr_active_features = egfr_features.loc[egfr_active_compounds]\n",
    "egfr_inactive_features = egfr_features.loc[egfr_inactive_compounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data so that each feature is normalized and can be compared to other features\n",
    "min_max_scaler = preprocessing.MinMaxScaler() #fits data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the active compounds\n",
    "egfr_active_features_norm = pd.DataFrame(min_max_scaler.fit_transform(egfr_active_features), \n",
    "                                         index=egfr_active_features.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the inactive compounds\n",
    "egfr_inactive_features_norm = pd.DataFrame(min_max_scaler.fit_transform(egfr_inactive_features), \n",
    "                                           index=egfr_inactive_features.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates from all_features - can also use DataFrame.drop_duplicates()\n",
    "all_features_cleaned = all_features.loc[list(set(all_features.index.values) - set(egfr_compounds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the database\n",
    "all_features_cleaned_norm = pd.DataFrame(min_max_scaler.fit_transform(all_features_cleaned), index=all_features_cleaned.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprep(active, rest, size, seed):\n",
    "    #create the query from a random sample of the data\n",
    "    size = int(active.shape[0] * size + .5)\n",
    "    query = active.sample(n=size, random_state=seed)\n",
    "    \n",
    "    #remove the query, then concatenate the remaining data for training\n",
    "    sub = list(set(active.index.values) - set(query.index.values))\n",
    "    active_minus_query = active.loc[sub]\n",
    "    database = pd.concat([active_minus_query] + rest)\n",
    "    \n",
    "    return database, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAnnoyModel(database, n_neighbors, metric, n_trees):\n",
    "    #create model - first argument is the length of the vectors\n",
    "    index = annoy.AnnoyIndex(database.shape[1], metric=metric)\n",
    "    \n",
    "    #add training data\n",
    "    start = time.time()\n",
    "    \n",
    "    #note that this is much slower than the other models because the data must be\n",
    "    #added row-by-row instead of the entire database at once\n",
    "    for i in range(database.shape[0]):\n",
    "        index.add_item(i, database.loc[database.index.values[i]])\n",
    "    \n",
    "    #build trees\n",
    "    index.build(n_trees)\n",
    "    end = time.time()\n",
    "    \n",
    "    build_time = end - start\n",
    "    \n",
    "    return index, build_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAnnoyQuery(model, query, n_neighbors, database, active):\n",
    "    indices = []\n",
    "    \n",
    "    #run query\n",
    "    start = time.time()\n",
    "    for j in range(query.shape[0]):\n",
    "        i = model.get_nns_by_vector(query.loc[query.index.values[j]], n_neighbors)\n",
    "        indices.append(i)\n",
    "    end = time.time()\n",
    "    \n",
    "    query_time  = end - start\n",
    "    \n",
    "    #assess the quality of the results - how many of the neighbors are in the success dataframe\n",
    "    sum = 0\n",
    "    for i in indices:\n",
    "        count = 0\n",
    "        for j in i:\n",
    "            if database.index.values[j] in active.index.values:\n",
    "                count += 1\n",
    "        sum += count / float(k)\n",
    "    average = sum / query.shape[0]\n",
    "    \n",
    "    return average, query_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annoyNN(active, rest, size, n_neighbors, metric, n_trees, seed):\n",
    "    #prepare the data\n",
    "    database, query = dataprep(active, rest, size, seed)\n",
    "    \n",
    "    #build the model\n",
    "    model, build_time = buildAnnoyModel(database, n_neighbors, metric, n_trees)\n",
    "    \n",
    "    #run the query\n",
    "    average, query_time = runAnnoyQuery(model, query, n_neighbors, database, active)\n",
    " \n",
    "    #return the results in a table\n",
    "    d = OrderedDict({'algorithm/index':['Annoy' + ' (' + str(n_trees) + ' trees)'], 'metric':[metric], \n",
    "                     'n_neighbors':[n_neighbors], 'query size':[size], 'build time (s)':[build_time], \n",
    "                     'query time (s)':[query_time], 'quality':[average], 'seed':[seed]})\n",
    "    \n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = annoyNN(egfr_active_features_norm, [stuff_cleaned_norm, egfr_inactive_features_norm], 0.2, 100, 'euclidean', 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for metric in ['angular', 'euclidean', 'manhattan', 'hamming']:\n",
    "    for n_trees in [5, 10, 20]:\n",
    "        temp.append(annoyNN(active=egfr_active_features_norm, rest=[stuff_cleaned_norm, egfr_inactive_features_norm], \n",
    "                            size=0.2, n_neighbors=100, metric=metric, n_trees=n_trees, seed=0))\n",
    "a = pd.concat(temp)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(12):\n",
    "    plt.scatter(a[i:i+1]['query time (s)'], a[i:i+1]['quality'], s=10)\n",
    "plt.ylim(0.995, 1)\n",
    "plt.xlabel('query time (s)')\n",
    "plt.ylabel('quality')\n",
    "plt.legend(['annoy/angular/5', 'annoy/angular/10', 'annoy/angular/15', \n",
    "            'annoy/euclidean/5', 'annoy/euclidean/10', 'annoy/euclidean/15', \n",
    "            'annoy/manhattan/5', 'annoy/manhattan/10', 'annoy/manhattan/15', \n",
    "            'annoy/hamming/5', 'annoy/hamming/10', 'annoy/hamming/15'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(12):\n",
    "    plt.scatter(a[i:i+1]['build time (s)'], a[i:i+1]['quality'], s=10)\n",
    "plt.ylim(0.995, 1)\n",
    "plt.xlabel('build time (s)')\n",
    "plt.ylabel('quality')\n",
    "plt.legend(['annoy/angular/5', 'annoy/angular/10', 'annoy/angular/15', \n",
    "            'annoy/euclidean/5', 'annoy/euclidean/10', 'annoy/euclidean/15', \n",
    "            'annoy/manhattan/5', 'annoy/manhattan/10', 'annoy/manhattan/15', \n",
    "            'annoy/hamming/5', 'annoy/hamming/10', 'annoy/hamming/15'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
